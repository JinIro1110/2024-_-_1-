{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "78e7bbd9bda24738bef066f2b08755dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_21f45334d54f46269c02389fca74995f",
              "IPY_MODEL_72cf6f1c182c43668331cc7d954673fb",
              "IPY_MODEL_5808c1fe50004e2fbdd5e2b4101fb3a2"
            ],
            "layout": "IPY_MODEL_70e97f16dc0b4cb1968fea1e1984dad3"
          }
        },
        "21f45334d54f46269c02389fca74995f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a17fe7c38cf549c48eb0ec4f2832c9a2",
            "placeholder": "​",
            "style": "IPY_MODEL_7c79eb1117514d9baeee61b1a931534f",
            "value": "tokenizer.json: 100%"
          }
        },
        "72cf6f1c182c43668331cc7d954673fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5468c693600c4c4a913a1efd305e3776",
            "max": 2825034,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_118db48b64c54389a70324d665c8c103",
            "value": 2825034
          }
        },
        "5808c1fe50004e2fbdd5e2b4101fb3a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2eb76f1e6ac34574bce7381d0aebfa8a",
            "placeholder": "​",
            "style": "IPY_MODEL_ec5f3b7baa6c4782b14c51a2881829ee",
            "value": " 2.83M/2.83M [00:00&lt;00:00, 5.74MB/s]"
          }
        },
        "70e97f16dc0b4cb1968fea1e1984dad3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a17fe7c38cf549c48eb0ec4f2832c9a2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7c79eb1117514d9baeee61b1a931534f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5468c693600c4c4a913a1efd305e3776": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "118db48b64c54389a70324d665c8c103": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2eb76f1e6ac34574bce7381d0aebfa8a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ec5f3b7baa6c4782b14c51a2881829ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8f8113b722a54ed68e2a36fa7e769a3a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_051d41a649c04f508c45e3ae10e76e2b",
              "IPY_MODEL_946326a8bef449ff979060b1c3324e59",
              "IPY_MODEL_2542e146e6cb44d1902a57aae7b1049a"
            ],
            "layout": "IPY_MODEL_b070ac4dbbe14753944bfaad85f20ce2"
          }
        },
        "051d41a649c04f508c45e3ae10e76e2b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7dece6fd19814126a8eece91fcae4458",
            "placeholder": "​",
            "style": "IPY_MODEL_02f177b4c8b34d9685da8835e026a8cd",
            "value": "config.json: 100%"
          }
        },
        "946326a8bef449ff979060b1c3324e59": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dd4d12b163bb44fd8b20bcb62646bb37",
            "max": 1000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fb5a276885df48af939e5948baa43912",
            "value": 1000
          }
        },
        "2542e146e6cb44d1902a57aae7b1049a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2b489c21ac22422baa0c7b7fecb0d202",
            "placeholder": "​",
            "style": "IPY_MODEL_6227aed118b040f9a6e8613d54b0448b",
            "value": " 1.00k/1.00k [00:00&lt;00:00, 88.1kB/s]"
          }
        },
        "b070ac4dbbe14753944bfaad85f20ce2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7dece6fd19814126a8eece91fcae4458": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "02f177b4c8b34d9685da8835e026a8cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dd4d12b163bb44fd8b20bcb62646bb37": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fb5a276885df48af939e5948baa43912": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2b489c21ac22422baa0c7b7fecb0d202": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6227aed118b040f9a6e8613d54b0448b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "UUxvxG4jC_Im",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "407a1cda-055e-4419-e4c2-8fee6918f51f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Collecting accelerate\n",
            "  Downloading accelerate-0.31.0-py3-none-any.whl (309 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m309.4/309.4 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (24.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.1)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.3.0+cu121)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.23.4)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.4.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.15.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.12.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.3.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->accelerate)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.5.40-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m69.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (4.66.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2024.6.2)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, accelerate\n",
            "Successfully installed accelerate-0.31.0 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.40 nvidia-nvtx-cu12-12.1.105\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.41.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.15.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.23.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.5.15)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.4)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.0->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.0->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.6.2)\n",
            "Collecting kss\n",
            "  Downloading kss-6.0.4.tar.gz (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting emoji==1.2.0 (from kss)\n",
            "  Downloading emoji-1.2.0-py3-none-any.whl (131 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m131.3/131.3 kB\u001b[0m \u001b[31m22.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pecab (from kss)\n",
            "  Downloading pecab-1.0.8.tar.gz (26.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.4/26.4 MB\u001b[0m \u001b[31m68.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from kss) (3.3)\n",
            "Collecting jamo (from kss)\n",
            "  Downloading jamo-0.4.1-py3-none-any.whl (9.5 kB)\n",
            "Collecting hangul-jamo (from kss)\n",
            "  Downloading hangul_jamo-1.0.1-py3-none-any.whl (4.4 kB)\n",
            "Collecting tossi (from kss)\n",
            "  Downloading tossi-0.3.1.tar.gz (11 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting distance (from kss)\n",
            "  Downloading Distance-0.1.3.tar.gz (180 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m180.3/180.3 kB\u001b[0m \u001b[31m28.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pyyaml==6.0 (from kss)\n",
            "  Downloading PyYAML-6.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (682 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m682.2/682.2 kB\u001b[0m \u001b[31m61.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting unidecode (from kss)\n",
            "  Downloading Unidecode-1.3.8-py3-none-any.whl (235 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m235.5/235.5 kB\u001b[0m \u001b[31m36.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting cmudict (from kss)\n",
            "  Downloading cmudict-1.0.24-py3-none-any.whl (939 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m939.4/939.4 kB\u001b[0m \u001b[31m71.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting koparadigm (from kss)\n",
            "  Downloading koparadigm-0.10.0-py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m88.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting kollocate (from kss)\n",
            "  Downloading kollocate-0.0.2-py3-none-any.whl (72.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.2/72.2 MB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting bs4 (from kss)\n",
            "  Downloading bs4-0.0.2-py2.py3-none-any.whl (1.2 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from kss) (1.25.2)\n",
            "Requirement already satisfied: pytest in /usr/local/lib/python3.10/dist-packages (from kss) (7.4.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from kss) (1.11.4)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from bs4->kss) (4.12.3)\n",
            "Requirement already satisfied: importlib-metadata>=5 in /usr/local/lib/python3.10/dist-packages (from cmudict->kss) (7.1.0)\n",
            "Requirement already satisfied: importlib-resources>=5 in /usr/local/lib/python3.10/dist-packages (from cmudict->kss) (6.4.0)\n",
            "Collecting whoosh (from kollocate->kss)\n",
            "  Downloading Whoosh-2.7.4-py2.py3-none-any.whl (468 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m468.8/468.8 kB\u001b[0m \u001b[31m55.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting xlrd==1.2.0 (from koparadigm->kss)\n",
            "  Downloading xlrd-1.2.0-py2.py3-none-any.whl (103 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.3/103.3 kB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyarrow in /usr/local/lib/python3.10/dist-packages (from pecab->kss) (14.0.2)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from pecab->kss) (2024.5.15)\n",
            "Requirement already satisfied: iniconfig in /usr/local/lib/python3.10/dist-packages (from pytest->kss) (2.0.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from pytest->kss) (24.1)\n",
            "Requirement already satisfied: pluggy<2.0,>=0.12 in /usr/local/lib/python3.10/dist-packages (from pytest->kss) (1.5.0)\n",
            "Requirement already satisfied: exceptiongroup>=1.0.0rc8 in /usr/local/lib/python3.10/dist-packages (from pytest->kss) (1.2.1)\n",
            "Requirement already satisfied: tomli>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from pytest->kss) (2.0.1)\n",
            "Requirement already satisfied: bidict in /usr/local/lib/python3.10/dist-packages (from tossi->kss) (0.23.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from tossi->kss) (1.16.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata>=5->cmudict->kss) (3.19.2)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->bs4->kss) (2.5)\n",
            "Building wheels for collected packages: kss, distance, pecab, tossi\n",
            "  Building wheel for kss (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for kss: filename=kss-6.0.4-cp310-cp310-linux_x86_64.whl size=1446484 sha256=c4dcc16b5c8c7f71829ed0c9b6f48971b0d2bfb2c3249d6302ad1c00d5029cc6\n",
            "  Stored in directory: /root/.cache/pip/wheels/dd/70/d5/c9308346829b1eb9e7267d74696919d2453aee6ce350f98b3b\n",
            "  Building wheel for distance (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for distance: filename=Distance-0.1.3-py3-none-any.whl size=16258 sha256=33eaf590b0b56aaa4a4d12aa6b6e944fadf9c01cc153d2d82ad72e374569193c\n",
            "  Stored in directory: /root/.cache/pip/wheels/e8/bb/de/f71bf63559ea9a921059a5405806f7ff6ed612a9231c4a9309\n",
            "  Building wheel for pecab (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pecab: filename=pecab-1.0.8-py3-none-any.whl size=26646664 sha256=d55dd303b91400a99309935303f94ce979b906bea0e5dc4e53bdc3c76513d2ef\n",
            "  Stored in directory: /root/.cache/pip/wheels/5c/6f/b4/ab61b8863d7d8b1409def8ae31adcaa089fa91b8d022ec309d\n",
            "  Building wheel for tossi (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tossi: filename=tossi-0.3.1-py3-none-any.whl size=12130 sha256=7b51068ef8c890b2b487b543ac024c0c96cf519741121bda47033a9dd0b5c6dd\n",
            "  Stored in directory: /root/.cache/pip/wheels/a7/18/60/1094a6fe93c8063efcd3e6700d09328216682e495a3c51af9f\n",
            "Successfully built kss distance pecab tossi\n",
            "Installing collected packages: whoosh, jamo, hangul-jamo, emoji, distance, xlrd, unidecode, tossi, pyyaml, kollocate, pecab, koparadigm, cmudict, bs4, kss\n",
            "  Attempting uninstall: xlrd\n",
            "    Found existing installation: xlrd 2.0.1\n",
            "    Uninstalling xlrd-2.0.1:\n",
            "      Successfully uninstalled xlrd-2.0.1\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 6.0.1\n",
            "    Uninstalling PyYAML-6.0.1:\n",
            "      Successfully uninstalled PyYAML-6.0.1\n",
            "Successfully installed bs4-0.0.2 cmudict-1.0.24 distance-0.1.3 emoji-1.2.0 hangul-jamo-1.0.1 jamo-0.4.1 kollocate-0.0.2 koparadigm-0.10.0 kss-6.0.4 pecab-1.0.8 pyyaml-6.0 tossi-0.3.1 unidecode-1.3.8 whoosh-2.7.4 xlrd-1.2.0\n",
            "Collecting datasets\n",
            "  Downloading datasets-2.20.0-py3-none-any.whl (547 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m547.8/547.8 kB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.15.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.25.2)\n",
            "Collecting pyarrow>=15.0.0 (from datasets)\n",
            "  Downloading pyarrow-16.1.0-cp310-cp310-manylinux_2_28_x86_64.whl (40.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.8/40.8 MB\u001b[0m \u001b[31m41.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m20.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.0.3)\n",
            "Collecting requests>=2.32.2 (from datasets)\n",
            "  Downloading requests-2.32.3-py3-none-any.whl (64 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.9/64.9 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.4)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m28.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multiprocess (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]<=2024.5.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.5)\n",
            "Requirement already satisfied: huggingface-hub>=0.21.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.23.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.2->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2024.6.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
            "Installing collected packages: xxhash, requests, pyarrow, dill, multiprocess, datasets\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.31.0\n",
            "    Uninstalling requests-2.31.0:\n",
            "      Successfully uninstalled requests-2.31.0\n",
            "  Attempting uninstall: pyarrow\n",
            "    Found existing installation: pyarrow 14.0.2\n",
            "    Uninstalling pyarrow-14.0.2:\n",
            "      Successfully uninstalled pyarrow-14.0.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "cudf-cu12 24.4.1 requires pyarrow<15.0.0a0,>=14.0.1, but you have pyarrow 16.1.0 which is incompatible.\n",
            "google-colab 1.0.0 requires requests==2.31.0, but you have requests 2.32.3 which is incompatible.\n",
            "ibis-framework 8.0.0 requires pyarrow<16,>=2, but you have pyarrow 16.1.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed datasets-2.20.0 dill-0.3.8 multiprocess-0.70.16 pyarrow-16.1.0 requests-2.32.3 xxhash-3.4.1\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "! pip install -U accelerate\n",
        "! pip install -U transformers\n",
        "! pip install kss\n",
        "! pip install datasets"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "import torch\n",
        "from transformers import GPT2LMHeadModel, GPT2Tokenizer, Trainer, TrainingArguments, EarlyStoppingCallback, PreTrainedTokenizerFast\n",
        "from torch.utils.data import Dataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "from datasets import load_dataset\n",
        "from kss import split_sentences\n",
        "import itertools\n",
        "import random\n",
        "\n",
        "# 토크나이저와 모델 로드\n",
        "tokenizer = PreTrainedTokenizerFast.from_pretrained(\"skt/kogpt2-base-v2\",\n",
        "  bos_token='</s>', eos_token='</s>', unk_token='<unk>',\n",
        "  pad_token='<pad>', mask_token='<mask>')\n",
        "model = GPT2LMHeadModel.from_pretrained(\"skt/kogpt2-base-v2\")\n",
        "\n",
        "# 데이터 읽기 함수\n",
        "def read_tales(file_path):\n",
        "    with open(file_path, 'r', encoding='utf-8') as f:\n",
        "        tales = f.read().strip().split('///')\n",
        "\n",
        "    return [tale.strip() for tale in tales if tale.strip()]\n",
        "\n",
        "# 데이터셋 클래스\n",
        "class TaleDataset(Dataset):\n",
        "    def __init__(self, tales, tokenizer, max_length=512):\n",
        "        self.tokenizer = tokenizer\n",
        "        self.tales = tales\n",
        "        self.max_length = max_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.tales)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        tale = self.tales[idx]\n",
        "        encoding = self.tokenizer(tale, truncation=True, max_length=self.max_length, padding=\"max_length\", return_tensors=\"pt\")\n",
        "        return {\n",
        "            'input_ids': encoding['input_ids'].flatten(),\n",
        "            'attention_mask': encoding['attention_mask'].flatten()\n",
        "        }\n",
        "\n",
        "# 데이터 콜레이터\n",
        "def data_collator(features):\n",
        "    batch = tokenizer.pad(features, padding=True, return_tensors=\"pt\")\n",
        "    batch['labels'] = batch['input_ids'].clone()\n",
        "    return batch\n",
        "\n",
        "# Perplexity 계산 함수\n",
        "def calculate_perplexity(model, tokenizer, tales, max_samples=100, batch_size=8, max_length=512):\n",
        "    model.eval()\n",
        "    total_loss = 0.0\n",
        "    total_length = 0\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model.to(device)\n",
        "\n",
        "    random.shuffle(tales)\n",
        "    tales = tales[:max_samples]\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i in range(0, len(tales), batch_size):\n",
        "            batch = tales[i:i + batch_size]\n",
        "            encodings = tokenizer(batch, return_tensors='pt', truncation=True, max_length=max_length, padding=True)\n",
        "            input_ids = encodings.input_ids.to(device)\n",
        "            attention_mask = encodings.attention_mask.to(device)\n",
        "\n",
        "            outputs = model(input_ids, attention_mask=attention_mask, labels=input_ids)\n",
        "            loss = outputs.loss\n",
        "\n",
        "            total_loss += loss.item() * torch.sum(attention_mask).item()\n",
        "            total_length += torch.sum(attention_mask).item()\n",
        "\n",
        "    if total_length == 0:\n",
        "        print(\"Warning: No valid inputs found. Cannot calculate perplexity.\")\n",
        "        return float('inf')\n",
        "\n",
        "    perplexity = math.exp(total_loss / total_length)\n",
        "    return perplexity\n",
        "\n",
        "\n",
        "\n",
        "# 동화 데이터 로드\n",
        "tales = read_tales('/content/drive/MyDrive/Tale/processed_final.txt')\n",
        "train_tales, val_tales = train_test_split(tales, test_size=0.1)\n",
        "\n",
        "# 데이터셋 생성\n",
        "train_dataset = TaleDataset(train_tales, tokenizer)\n",
        "val_dataset = TaleDataset(val_tales, tokenizer)\n",
        "\n",
        "# 초기 모델의 perplexity 계산\n",
        "initial_model = GPT2LMHeadModel.from_pretrained(\"skt/kogpt2-base-v2\")\n",
        "initial_model.config.pad_token_id = tokenizer.pad_token_id\n",
        "initial_perplexity = calculate_perplexity(initial_model, tokenizer, val_tales)\n",
        "print(f\"Initial model perplexity: {initial_perplexity:.2f}\")\n",
        "\n",
        "\n",
        "# 하이퍼파라미터 그리드 정의\n",
        "param_grid = {\n",
        "    'learning_rate': [1e-4, 3e-4, 1e-5],\n",
        "    'per_device_train_batch_size': [8],\n",
        "    'num_train_epochs': [5, 10],\n",
        "    'weight_decay': [0.01, 0.1]\n",
        "}\n",
        "\n",
        "# 모든 하이퍼파라미터 조합 생성\n",
        "param_combinations = list(itertools.product(*param_grid.values()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XUtH_fqtAmtx",
        "outputId": "edf922fe-d519-441b-c03e-87d786076c7c"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'GPT2Tokenizer'. \n",
            "The class this function is called from is 'PreTrainedTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial model perplexity: 7564.67\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "import torch\n",
        "import os\n",
        "\n",
        "best_perplexity = float('inf')\n",
        "best_params = None\n",
        "\n",
        "output_dir = '/content/drive/MyDrive/Tale/max_length512'\n",
        "\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "with open(os.path.join(output_dir, 'results.csv'), 'w', newline='') as file:\n",
        "    writer = csv.writer(file)\n",
        "    writer.writerow([\"LR\", \"Batch Size\", \"Epochs\", \"Weight Decay\", \"Perplexity\", \"Improvement\"])\n",
        "\n",
        "    # 각 하이퍼파라미터 조합에 대해 학습 및 평가\n",
        "    for i, params in enumerate(param_combinations):\n",
        "        try:\n",
        "            print(f\"Training model {i+1}/{len(param_combinations)}\")\n",
        "\n",
        "            # GPU 메모리 정리\n",
        "            torch.cuda.empty_cache()\n",
        "\n",
        "            lr, batch_size, epochs, wd = params\n",
        "\n",
        "            # Early Stopping 콜백 생성\n",
        "            early_stopping_callback = EarlyStoppingCallback(\n",
        "                early_stopping_patience=3,\n",
        "                early_stopping_threshold=0.01\n",
        "            )\n",
        "\n",
        "            # 학습 인자 설정\n",
        "            training_args = TrainingArguments(\n",
        "                output_dir=f\"/content/drive/MyDrive/Tale/max_length512/results_{i}\",\n",
        "                num_train_epochs=epochs,\n",
        "                per_device_train_batch_size=batch_size,\n",
        "                per_device_eval_batch_size=batch_size,\n",
        "                warmup_steps=500,\n",
        "                weight_decay=wd,\n",
        "                learning_rate=lr,\n",
        "                logging_dir=f'/content/drive/MyDrive/Tale/max_length512/logs_{i}',\n",
        "                logging_steps=10,\n",
        "                eval_strategy=\"epoch\",\n",
        "                save_strategy=\"epoch\",\n",
        "                load_best_model_at_end=True,\n",
        "                metric_for_best_model=\"eval_loss\",\n",
        "            )\n",
        "\n",
        "            # 모델 초기화\n",
        "            model = GPT2LMHeadModel.from_pretrained(\"skt/kogpt2-base-v2\")\n",
        "            model.config.pad_token_id = tokenizer.pad_token_id\n",
        "\n",
        "            # Trainer 생성\n",
        "            trainer = Trainer(\n",
        "                model=model,\n",
        "                args=training_args,\n",
        "                train_dataset=train_dataset,\n",
        "                eval_dataset=val_dataset,\n",
        "                data_collator=data_collator,\n",
        "                callbacks=[early_stopping_callback]\n",
        "            )\n",
        "\n",
        "            # 학습 실행\n",
        "            trainer.train()\n",
        "\n",
        "            # 모델 저장\n",
        "            trainer.save_model(f\"/content/drive/MyDrive/Tale/max_length512/results_{i}/final_model\")\n",
        "\n",
        "            # 최종 모델 Perplexity 측정\n",
        "            final_model = GPT2LMHeadModel.from_pretrained(f\"/content/drive/MyDrive/Tale/max_length512/results_{i}/final_model\")\n",
        "            final_model.to('cpu')  # CPU로 모델 이동\n",
        "            final_model.config.pad_token_id = tokenizer.pad_token_id\n",
        "            final_perplexity = calculate_perplexity(final_model, tokenizer, val_tales)\n",
        "            print(f\"Final model perplexity: {final_perplexity:.2f}\")\n",
        "\n",
        "            # Perplexity 개선율 계산\n",
        "            improvement = (initial_perplexity - final_perplexity) / initial_perplexity * 100\n",
        "            print(f\"Perplexity improvement: {improvement:.2f}%\")\n",
        "\n",
        "            # CSV에 결과 쓰기\n",
        "            writer.writerow([lr, batch_size, epochs, wd, final_perplexity, improvement])\n",
        "            file.flush()  # 즉시 파일에 쓰기\n",
        "\n",
        "            # 중간 결과 저장\n",
        "            if final_perplexity < best_perplexity:\n",
        "                best_perplexity = final_perplexity\n",
        "                best_params = params\n",
        "                torch.save({\n",
        "                    'best_params': best_params,\n",
        "                    'best_perplexity': best_perplexity,\n",
        "                    'model_state_dict': final_model.state_dict()\n",
        "                }, '/content/drive/MyDrive/Tale/max_length512/best_model_checkpoint.pth')\n",
        "\n",
        "            print(f\"Parameters: LR={lr}, Batch Size={batch_size}, Epochs={epochs}, Weight Decay={wd}\")\n",
        "            print(\"--------------------\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error occurred during training: {str(e)}\")\n",
        "            continue  # 다음 실험으로 계속 진행\n",
        "\n",
        "print(f\"Best parameters: LR={best_params[0]}, Batch Size={best_params[1]}, Epochs={best_params[2]}, Weight Decay={best_params[3]}\")\n",
        "print(f\"Best perplexity: {best_perplexity:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "CMcgb9jXzIBL",
        "outputId": "4150fffc-1f98-462b-a025-32780e225ead"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training model 1/12\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='610' max='610' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [610/610 07:44, Epoch 5/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.865700</td>\n",
              "      <td>1.937950</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.884400</td>\n",
              "      <td>1.896484</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>1.864100</td>\n",
              "      <td>1.897948</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>1.620500</td>\n",
              "      <td>1.896670</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>1.436600</td>\n",
              "      <td>1.842760</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "There were missing keys in the checkpoint model loaded: ['lm_head.weight'].\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final model perplexity: 7.21\n",
            "Perplexity improvement: 99.90%\n",
            "Parameters: LR=0.0001, Batch Size=8, Epochs=5, Weight Decay=0.01\n",
            "--------------------\n",
            "Training model 2/12\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='610' max='610' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [610/610 07:46, Epoch 5/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.865700</td>\n",
              "      <td>1.937918</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.890500</td>\n",
              "      <td>1.896007</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>1.862600</td>\n",
              "      <td>1.894209</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>1.619800</td>\n",
              "      <td>1.897114</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>1.433800</td>\n",
              "      <td>1.840290</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "There were missing keys in the checkpoint model loaded: ['lm_head.weight'].\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final model perplexity: 6.56\n",
            "Perplexity improvement: 99.91%\n",
            "Parameters: LR=0.0001, Batch Size=8, Epochs=5, Weight Decay=0.1\n",
            "--------------------\n",
            "Training model 3/12\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='610' max='1220' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 610/1220 07:44 < 07:46, 1.31 it/s, Epoch 5/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.865700</td>\n",
              "      <td>1.937950</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.884400</td>\n",
              "      <td>1.896484</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>1.864100</td>\n",
              "      <td>1.897948</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>1.620500</td>\n",
              "      <td>1.896670</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>1.560900</td>\n",
              "      <td>1.889005</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "There were missing keys in the checkpoint model loaded: ['lm_head.weight'].\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final model perplexity: 7.12\n",
            "Perplexity improvement: 99.91%\n",
            "Parameters: LR=0.0001, Batch Size=8, Epochs=10, Weight Decay=0.01\n",
            "--------------------\n",
            "Training model 4/12\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1098' max='1220' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1098/1220 13:55 < 01:33, 1.31 it/s, Epoch 9/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.865700</td>\n",
              "      <td>1.937918</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.890500</td>\n",
              "      <td>1.896006</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>1.862600</td>\n",
              "      <td>1.894209</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>1.619800</td>\n",
              "      <td>1.897114</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>1.565100</td>\n",
              "      <td>1.882553</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>1.202100</td>\n",
              "      <td>1.867802</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.869800</td>\n",
              "      <td>1.871969</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.773200</td>\n",
              "      <td>1.872391</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.640200</td>\n",
              "      <td>1.872451</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "There were missing keys in the checkpoint model loaded: ['lm_head.weight'].\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final model perplexity: 6.47\n",
            "Perplexity improvement: 99.91%\n",
            "Parameters: LR=0.0001, Batch Size=8, Epochs=10, Weight Decay=0.1\n",
            "--------------------\n",
            "Training model 5/12\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='488' max='610' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [488/610 06:11 < 01:33, 1.31 it/s, Epoch 4/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.885000</td>\n",
              "      <td>1.959723</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.923500</td>\n",
              "      <td>1.982850</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>1.913800</td>\n",
              "      <td>2.036334</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>1.660100</td>\n",
              "      <td>2.090192</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "There were missing keys in the checkpoint model loaded: ['lm_head.weight'].\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final model perplexity: 7.56\n",
            "Perplexity improvement: 99.90%\n",
            "Parameters: LR=0.0003, Batch Size=8, Epochs=5, Weight Decay=0.01\n",
            "--------------------\n",
            "Training model 6/12\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='488' max='610' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [488/610 06:11 < 01:33, 1.31 it/s, Epoch 4/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.884700</td>\n",
              "      <td>1.961082</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.917600</td>\n",
              "      <td>1.982085</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>1.914400</td>\n",
              "      <td>2.044383</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>1.666900</td>\n",
              "      <td>2.092590</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "There were missing keys in the checkpoint model loaded: ['lm_head.weight'].\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final model perplexity: 7.09\n",
            "Perplexity improvement: 99.91%\n",
            "Parameters: LR=0.0003, Batch Size=8, Epochs=5, Weight Decay=0.1\n",
            "--------------------\n",
            "Training model 7/12\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='488' max='1220' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 488/1220 06:11 < 09:20, 1.31 it/s, Epoch 4/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.885000</td>\n",
              "      <td>1.959724</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.923500</td>\n",
              "      <td>1.982850</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>1.913800</td>\n",
              "      <td>2.036334</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>1.660100</td>\n",
              "      <td>2.090192</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "There were missing keys in the checkpoint model loaded: ['lm_head.weight'].\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final model perplexity: 7.64\n",
            "Perplexity improvement: 99.90%\n",
            "Parameters: LR=0.0003, Batch Size=8, Epochs=10, Weight Decay=0.01\n",
            "--------------------\n",
            "Training model 8/12\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='488' max='1220' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 488/1220 06:09 < 09:15, 1.32 it/s, Epoch 4/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.884700</td>\n",
              "      <td>1.961082</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.917600</td>\n",
              "      <td>1.982085</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>1.914400</td>\n",
              "      <td>2.044383</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>1.666900</td>\n",
              "      <td>2.092590</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "There were missing keys in the checkpoint model loaded: ['lm_head.weight'].\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final model perplexity: 7.99\n",
            "Perplexity improvement: 99.89%\n",
            "Parameters: LR=0.0003, Batch Size=8, Epochs=10, Weight Decay=0.1\n",
            "--------------------\n",
            "Training model 9/12\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='610' max='610' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [610/610 07:43, Epoch 5/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>2.021700</td>\n",
              "      <td>2.039129</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.999800</td>\n",
              "      <td>1.939631</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>2.019800</td>\n",
              "      <td>1.905551</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>1.870500</td>\n",
              "      <td>1.885407</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>1.978900</td>\n",
              "      <td>1.866644</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "There were missing keys in the checkpoint model loaded: ['lm_head.weight'].\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final model perplexity: 6.89\n",
            "Perplexity improvement: 99.91%\n",
            "Parameters: LR=1e-05, Batch Size=8, Epochs=5, Weight Decay=0.01\n",
            "--------------------\n",
            "Training model 10/12\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='610' max='610' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [610/610 07:43, Epoch 5/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>2.021700</td>\n",
              "      <td>2.039127</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.999800</td>\n",
              "      <td>1.939630</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>2.019800</td>\n",
              "      <td>1.905546</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>1.870400</td>\n",
              "      <td>1.885396</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>1.978900</td>\n",
              "      <td>1.866627</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "There were missing keys in the checkpoint model loaded: ['lm_head.weight'].\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final model perplexity: 6.50\n",
            "Perplexity improvement: 99.91%\n",
            "Parameters: LR=1e-05, Batch Size=8, Epochs=5, Weight Decay=0.1\n",
            "--------------------\n",
            "Training model 11/12\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1220' max='1220' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1220/1220 15:26, Epoch 10/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>2.021700</td>\n",
              "      <td>2.039129</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.999800</td>\n",
              "      <td>1.939631</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>2.019800</td>\n",
              "      <td>1.905551</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>1.870500</td>\n",
              "      <td>1.885407</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>1.987500</td>\n",
              "      <td>1.862615</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>1.784100</td>\n",
              "      <td>1.855447</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>1.596500</td>\n",
              "      <td>1.845306</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>1.679000</td>\n",
              "      <td>1.844709</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>1.678300</td>\n",
              "      <td>1.841450</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>1.762300</td>\n",
              "      <td>1.841015</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "There were missing keys in the checkpoint model loaded: ['lm_head.weight'].\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final model perplexity: 6.91\n",
            "Perplexity improvement: 99.91%\n",
            "Parameters: LR=1e-05, Batch Size=8, Epochs=10, Weight Decay=0.01\n",
            "--------------------\n",
            "Training model 12/12\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1220' max='1220' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1220/1220 15:26, Epoch 10/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>2.021700</td>\n",
              "      <td>2.039127</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.999800</td>\n",
              "      <td>1.939629</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>2.019800</td>\n",
              "      <td>1.905546</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>1.870400</td>\n",
              "      <td>1.885397</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>1.987500</td>\n",
              "      <td>1.862600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>1.784100</td>\n",
              "      <td>1.855421</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>1.596500</td>\n",
              "      <td>1.845273</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>1.679000</td>\n",
              "      <td>1.844665</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>1.678300</td>\n",
              "      <td>1.841400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>1.762200</td>\n",
              "      <td>1.840960</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "There were missing keys in the checkpoint model loaded: ['lm_head.weight'].\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final model perplexity: 6.27\n",
            "Perplexity improvement: 99.92%\n",
            "Parameters: LR=1e-05, Batch Size=8, Epochs=10, Weight Decay=0.1\n",
            "--------------------\n",
            "Best parameters: LR=1e-05, Batch Size=8, Epochs=10, Weight Decay=0.1\n",
            "Best perplexity: 6.27\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Y-2hVCpOWm03"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7cCfBcAQWm4z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "w5sau5s9Wm8m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-EDynlK2WnAG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ungzmCuLWnEI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "l5oNL1MoWnH8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DL5z6NUDWnLy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xfX8eIMCWnP5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bhww2no7WnTD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import GPT2LMHeadModel, PreTrainedTokenizerFast\n",
        "\n",
        "tokenizer = PreTrainedTokenizerFast.from_pretrained(\"skt/kogpt2-base-v2\",\n",
        "  bos_token='</s>', eos_token='</s>', unk_token='<unk>',\n",
        "  pad_token='<pad>', mask_token='<mask>')\n",
        "\n",
        "def generate_text(model_path, prompt, max_new_tokens=50):\n",
        "    model = GPT2LMHeadModel.from_pretrained(model_path)\n",
        "    model.config.pad_token_id = tokenizer.pad_token_id\n",
        "\n",
        "    input_ids = tokenizer.encode(prompt, return_tensors='pt', add_special_tokens=False)\n",
        "\n",
        "    output = model.generate(\n",
        "        input_ids,\n",
        "        max_new_tokens=max_new_tokens,\n",
        "        do_sample=True,\n",
        "        temperature=0.7,\n",
        "        top_k=50,\n",
        "        top_p=0.95,\n",
        "        no_repeat_ngram_size=2,\n",
        "        pad_token_id=tokenizer.pad_token_id,\n",
        "        eos_token_id=None,\n",
        "    )\n",
        "\n",
        "    generated_text = tokenizer.decode(output[0][len(input_ids[0]):], skip_special_tokens=True)\n",
        "\n",
        "    return generated_text.strip()\n",
        "\n",
        "prompt = \"고래 백경이는 \"\n",
        "\n",
        "for i in range(1, 37):\n",
        "    model_path = f\"/content/drive/MyDrive/Tale/batch_learning4/results_{i}/final_model\"\n",
        "    generated_text = generate_text(model_path, prompt)\n",
        "    print(generated_text)\n",
        "    print(\"-\" * 50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "78e7bbd9bda24738bef066f2b08755dc",
            "21f45334d54f46269c02389fca74995f",
            "72cf6f1c182c43668331cc7d954673fb",
            "5808c1fe50004e2fbdd5e2b4101fb3a2",
            "70e97f16dc0b4cb1968fea1e1984dad3",
            "a17fe7c38cf549c48eb0ec4f2832c9a2",
            "7c79eb1117514d9baeee61b1a931534f",
            "5468c693600c4c4a913a1efd305e3776",
            "118db48b64c54389a70324d665c8c103",
            "2eb76f1e6ac34574bce7381d0aebfa8a",
            "ec5f3b7baa6c4782b14c51a2881829ee",
            "8f8113b722a54ed68e2a36fa7e769a3a",
            "051d41a649c04f508c45e3ae10e76e2b",
            "946326a8bef449ff979060b1c3324e59",
            "2542e146e6cb44d1902a57aae7b1049a",
            "b070ac4dbbe14753944bfaad85f20ce2",
            "7dece6fd19814126a8eece91fcae4458",
            "02f177b4c8b34d9685da8835e026a8cd",
            "dd4d12b163bb44fd8b20bcb62646bb37",
            "fb5a276885df48af939e5948baa43912",
            "2b489c21ac22422baa0c7b7fecb0d202",
            "6227aed118b040f9a6e8613d54b0448b"
          ]
        },
        "id": "0rMniDehumSE",
        "outputId": "39ed71c8-91bd-4c80-8926-fb095d52c334"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/2.83M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "78e7bbd9bda24738bef066f2b08755dc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/1.00k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8f8113b722a54ed68e2a36fa7e769a3a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'GPT2Tokenizer'. \n",
            "The class this function is called from is 'PreTrainedTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "덫에 걸렸다  가까스로 탈출했어요. 는 이 이야기를 하며 자신을 뽐내고 있었죠.  의지할 수 있는 녀석에게 호의를 베풀어준 친구가 바로 공주님이셨답니다.\n",
            "--------------------------------------------------\n",
            "펭귄이 자신의 친구 냥 짹짹거리며 톡 웃고 있었어요.  \"펭! 뭔가 쿵, 윙,\"라며 친구가 말했어요, \"아!\"  \"나는\n",
            "--------------------------------------------------\n",
            "펭귄의 아름다운 깃털을 자랑했다.  그 모습을 보고 한 녀석들은 엄청 놀랐다.  뭔가 멋진 봤다. \n",
            "그래서 넌 왜 그래,? 괜찮은\n",
            "--------------------------------------------------\n",
            "펭귄의 아름다운 그림자에 반해 삐딱삐걱 딱 톡 웃지 않는 녀석.  어느 날 땡볕을 받으며 뽀얀 꼬리를 가진 깡충이는 자신의 얌전히 꼬리를 밟고\n",
            "--------------------------------------------------\n",
            "펭귄에 의해 꼼짝없이 덫에 걸려버리고 말았어요.  그 바람에 땡쥐와  톡이 날아갔어요! \"!\" ck 이 말은\n",
            "--------------------------------------------------\n",
            "덫에 걸려 가까스로 탈출했습니다.  하지만 그 과정에서 꼬리를 잃고 말았습니다..  황소들이 무거운 짐을 짊어지고 있음에도 탈출구가 막힌 게 백 경장의 발걸음을 멈추게 하곤 빈손으로 돌아가\n",
            "--------------------------------------------------\n",
            "덫에 걸린 상태였어요.  그래서 나뭇가지 아래에 구멍을 파서 매일 같이 보려고 했어요   그래서 백 경이는 물었어요, \"왜 거기서 잤어?\" \n",
            "\"응, 네\n",
            "--------------------------------------------------\n",
            "펭귄이 좋아해서, 자신이 좋아하는 나무를 이용해 자신의 몸을 보호할 수 있는 친구로 자랐어요.  친구는 그런 친구의 은혜를 모르는지 종종 자신의 운을 한탄하곤 했어요, 그래서 그가 짊어지고 있는 나뭇가지 사이에 구멍을\n",
            "--------------------------------------------------\n",
            "펭귄이 자신의 고래와 함께 평화롭게 살고 있었어요.  어느 날, 고래는 고래에게 말했어요, \"펭, 난 너가 좋아, 넌 고래도 좋아해!\"  고래가 고래를\n",
            "--------------------------------------------------\n",
            "덫에 걸려 가까스로 탈출했지만, 곧장 다른 족제비에게 붙잡히고 말았어요.  백경은 다시 한 번 자신의 신분을 증명하고 풀려날 수 있었어요!  백 경이는 그 후 얼마 살지 못하고\n",
            "--------------------------------------------------\n",
            "덫에 걸렸어요.  백 경이는 최대한 많은 물고기를 잡아서 자신의 생명을 구했답니다.  백경도 어항 속 동굴에 갇혔지만 탈출할 수 있었지요.  니다. 꼼짝\n",
            "--------------------------------------------------\n",
            "펭귄을 주워 먹자고 그럴듯한 핑계를 댔어요.  \"난 먹을 게 다 떨어지면 너도 나랑 같이 먹거라.\"  수도꼭지가 자신의 처지를 불쌍하다고 생각한 거지요..\n",
            "--------------------------------------------------\n",
            "덫에 걸린 상황에서 가까스로 탈출했지만, 그 과정에서 자신의 꼬리를 잃었어요.  그때부터 여우들은 남들 앞에 자신을 방어하기 위해 자주 남들을 내곤 했어요, 그래서 자신의 부족함이 눈에 띄지 않게 해달라 빌었지요.\"\n",
            "--------------------------------------------------\n",
            "펭귄의 그림자도 뽐내고 있어요.  \"우리 둘 다 사실입니다. 당신은 제 그림자라고 주장하셨어요. 저는 제가 그림자는 사실일 아침부터 잤어요..\"\n",
            " 그래서 쿵,\n",
            "--------------------------------------------------\n",
            "볕을 따며 몸을 으쓱거리며 말했어요.  \"내게 될 얘야.\"  훈장님은 그 말에 동의했습니다. 그러자 그 소식을 듣고 있던 구경꾼들 중 한 마리가 뒤를 밟고\n",
            "--------------------------------------------------\n",
            "볕을 때, 자신의 집에서 사는 자신의 고양이를 만났어요.  고양이는 고양이의 얼굴에 찡그려 자신의 입에서 뺄 채 눈물을 흘리며 고양이가 어디에 있는지 궁금해했어요, 고양이와 고양이, 고양이 쏙\n",
            "--------------------------------------------------\n",
            "볕을 따며 말했어요.  \"봄을 더워, 날씨가 더워서 그래, 내가 더 힘이 센 걸 알려줄게. 내가 그 추운 겨울을 끝내고 식탁을 준비해야 한.\"  하늘도 땅\n",
            "--------------------------------------------------\n",
            "펭귄에게 먹이를 주고 싶었어요.  그래서 고양이는 고양이를 위해 먹이를 찾아주었습니다.  콜래보레이션은 매일 반복되었습니다.! \n",
            "펭은 줘서 고맙\n",
            "--------------------------------------------------\n",
            "뭘 먹으려고 했어요.  그런데 갑자기 배가 고파서 배가 너무 고팠어요, 그래서 백경은이를 다시 먹기로 했죠.左左右右左 右에 있는 수탉이 너무 무서워서 수\n",
            "--------------------------------------------------\n",
            "펭귄의 뿔과 발톱을 보며 깜짝 놀랐어요.  그런데 뭔가 재미있는 게 있었어요!貴賤으로 인해 뻐꾸러기 환자도 함께 살게 되었어요, 高句麗\n",
            "--------------------------------------------------\n",
            "씩씩하게 말했어요.  \"무슨 일인데?\"告   苦 \"어떻게 하면 돼?\"\n",
            "백경이가 물었어요,高 增 \"아무도 그\n",
            "--------------------------------------------------\n",
            "넌 참을 수 없어.\n",
            "네가 네가 가진 장점을 살려줄 수 있다면 고마워. 어느 날 뭔가 이상한 일이 일어나서 그 문제를 해결하려 했어요.  하지만 너무 놀라서 다른 사람들을 설득했어요, 그\n",
            "--------------------------------------------------\n",
            "넌지시 꿈쩍도 하지 않고 그저 멍멍이만만 떠는 것 뿐이었어요.  하지만 그 애는 너무 무서워서 겁도 없이 자신의 두려움을 풀고 나왔어요, 그래서 백경이에게 말했어요\n",
            "--------------------------------------------------\n",
            "볕으로 둘러싸여 있었어요.  하지만 그는 아무리 작아서 그렇지 않아 아무 일도 하지 않았죠.  제사는 그의 소유자라 누구도 그를 내려다보았죠, 그래서 그는 그의 얼굴이 찡그려진 채로 말\n",
            "--------------------------------------------------\n",
            "볕을 받으며 햇살이 위로 비추고, 어느 날 밤, 그 날 아침 하늘에 아름다운 물고기가 자신의 집에서 살게 되었어요.  그때, 어부가 와서 같은 바다 마을로 나가려고 했어요? 쌔게 수영하는 물에서\n",
            "--------------------------------------------------\n",
            "쿵!  \"바로 앞에 있는 백조를 발견했으니?\"  차갑다고, \"왜 그래,\"라며 엄마도 말했어요.\n",
            "\"내 말대로 말했다.\" 라며\n",
            "--------------------------------------------------\n",
            "백조의 찬란한 빛들을 나는 것으로 착각했어요.! 그 까마귀는 바로 까마귀였어요? 봤답은 자신이 살던 것에 대해 사랑과 우정을 느낀다고 생각하다 말했죠. 그러자 백\n",
            "--------------------------------------------------\n",
            "뭘 못 살찐지 궁금하곤 했어요.  백광대가 자신의 새와 무슨 소원지에 대해 말했어요, \"우리도 나를 좋아야겠어. 내가 너를 사랑하겠다!\" 라며 그\n",
            "--------------------------------------------------\n",
            "볕에 나타나는 꽃들과 별들이 아름다운 꽃 사이에서 아름다운 빛에 살고 있었습니다.  그때 백사가 꽃들을 둘러보았습니다. 봤고, 그때 까마른 꽃들이 너를 사랑하던 까딱 안 보이더니 까마가 한 명\n",
            "--------------------------------------------------\n",
            "끙끙 앓으며 울었어요.  \"아! 정말 고마워. 내 너희 둘만 합쳐 살겠니!\"  또 다른 하나는 자신의 모습을 보려고 노력했어요 \n",
            "\"\n",
            "--------------------------------------------------\n",
            "뭘 먹어야 할까, 하고 물었어요.  \"이제 그만둬, 난 네게 무엇을 줄게.\"라고 말했어요  그러자 어린 소년이 말대꾸를 하며 대답했습니다. 高\n",
            "--------------------------------------------------\n",
            "뭘 먹이고 어떻게 사는 거야!\"  그가 대답했어요.  \n",
            "\"내가 먹을 것이 뭐야?\"하고 물었어요 \n",
            "그 순간,\n",
            "얼굴이 붉어하며 놀란\n",
            "--------------------------------------------------\n",
            "끙 앓으며 잠을 설었어요.  그런데 어느 날 저녁이 되자 목소리는 잠이 들었죠.  그래서 목소리도 잠에 들었지만 이번에는 목소도 잠을 자고 깨어났어요\n",
            "--------------------------------------------------\n",
            "뭔가 하고 놀고 놀다 그만 숨지고 말았어요.  그러자 엄마 염소가 말했어요, \"넌 왜 이래. 너무 겁이 많아서 그래,\"라며 엄마에게 말대꾸했습니다.\n",
            "--------------------------------------------------\n",
            "뭔가를 손에 쥐고서 숲으로 돌아왔어요.  그 뒤로 한 번은 개울물이 나왔어요!  그런데 이걸 보고 놀란 주인이 물었어요, \"어이없지!\"라며 그가 말했어\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "OSError",
          "evalue": "Incorrect path_or_model_id: '/content/drive/MyDrive/Tale/batch_learning/results_36/final_model'. Please provide either the path to a local folder or the repo_id of a model on the Hub.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mHFValidationError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/utils/hub.py\u001b[0m in \u001b[0;36mcached_file\u001b[0;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m    398\u001b[0m         \u001b[0;31m# Load from URL or cache if already cached\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 399\u001b[0;31m         resolved_file = hf_hub_download(\n\u001b[0m\u001b[1;32m    400\u001b[0m             \u001b[0mpath_or_repo_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_validators.py\u001b[0m in \u001b[0;36m_inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    105\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0marg_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"repo_id\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"from_id\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"to_id\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m                 \u001b[0mvalidate_repo_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_validators.py\u001b[0m in \u001b[0;36mvalidate_repo_id\u001b[0;34m(repo_id)\u001b[0m\n\u001b[1;32m    153\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mrepo_id\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m         raise HFValidationError(\n\u001b[0m\u001b[1;32m    155\u001b[0m             \u001b[0;34m\"Repo id must be in the form 'repo_name' or 'namespace/repo_name':\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mHFValidationError\u001b[0m: Repo id must be in the form 'repo_name' or 'namespace/repo_name': '/content/drive/MyDrive/Tale/batch_learning/results_36/final_model'. Use `repo_type` argument if needed.",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-2527a49b36ee>\u001b[0m in \u001b[0;36m<cell line: 32>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m37\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0mmodel_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"/content/drive/MyDrive/Tale/batch_learning/results_{i}/final_model\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m     \u001b[0mgenerated_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerated_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"-\"\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-2-2527a49b36ee>\u001b[0m in \u001b[0;36mgenerate_text\u001b[0;34m(model_path, prompt, max_new_tokens)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mgenerate_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprompt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_new_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGPT2LMHeadModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad_token_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad_token_id\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   3049\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPretrainedConfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3050\u001b[0m                 \u001b[0;31m# We make a call to the config file first (which may be absent) to get the commit hash as soon as possible\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3051\u001b[0;31m                 resolved_config_file = cached_file(\n\u001b[0m\u001b[1;32m   3052\u001b[0m                     \u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3053\u001b[0m                     \u001b[0mCONFIG_NAME\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/utils/hub.py\u001b[0m in \u001b[0;36mcached_file\u001b[0;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m    461\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mEnvironmentError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"There was a specific connection error when trying to load {path_or_repo_id}:\\n{err}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mHFValidationError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 463\u001b[0;31m         raise EnvironmentError(\n\u001b[0m\u001b[1;32m    464\u001b[0m             \u001b[0;34mf\"Incorrect path_or_model_id: '{path_or_repo_id}'. Please provide either the path to a local folder or the repo_id of a model on the Hub.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m         ) from e\n",
            "\u001b[0;31mOSError\u001b[0m: Incorrect path_or_model_id: '/content/drive/MyDrive/Tale/batch_learning/results_36/final_model'. Please provide either the path to a local folder or the repo_id of a model on the Hub."
          ]
        }
      ]
    }
  ]
}